{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Time  Size\n",
      "0     0.000000   462\n",
      "1     0.000653  1438\n",
      "2     0.000913  1438\n",
      "3     0.001166  1438\n",
      "4     0.001418  1438\n",
      "..         ...   ...\n",
      "629  26.582104   158\n",
      "630  26.582524   206\n",
      "631  26.693961   158\n",
      "632  28.291272   142\n",
      "633  28.346655   158\n",
      "\n",
      "[634 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import rdpcap\n",
    "import pandas as pd\n",
    "\n",
    "input_pcap_path = '../../data_processed/vc_200/alexa/total3/10/10.pcap'  # Replace with your actual path\n",
    "\n",
    "# Read packets from the pcap file\n",
    "packets = rdpcap(input_pcap_path)\n",
    "\n",
    "# Extract packet times and sizes\n",
    "times = [pkt.time for pkt in packets]\n",
    "sizes = [len(pkt) for pkt in packets]\n",
    "\n",
    "# Normalize the time to start from 0 by subtracting the first timestamp from all timestamps\n",
    "times = [t - times[0] for t in times]\n",
    "\n",
    "# Create a DataFrame from the normalized times and sizes\n",
    "df = pd.DataFrame({'Time': times, 'Size': sizes})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled data saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is the DataFrame from the previous step\n",
    "\n",
    "# Convert the Time column to a pandas datetime type for resampling\n",
    "df['Time'] = df['Time'].astype(float)\n",
    "\n",
    "# Convert the Time column to a pandas timedelta type for resampling\n",
    "df['Time'] = pd.to_timedelta(df['Time'], unit='s')\n",
    "\n",
    "# Set Time as the index\n",
    "df.set_index('Time', inplace=True)\n",
    "\n",
    "# Resample and sum up the sizes for each interval (0.2 seconds in this example)\n",
    "interval = '200L'  # 'L' stands for milliseconds\n",
    "resampled_df = df.resample(interval).sum()\n",
    "\n",
    "# Reset index to turn the Time back into a column and convert it back to seconds\n",
    "resampled_df.reset_index(inplace=True)\n",
    "resampled_df['Time'] = resampled_df['Time'].dt.total_seconds()\n",
    "\n",
    "# Specify the output CSV file path\n",
    "output_csv_path = 'output.csv'  # Replace with your desired output CSV file path\n",
    "\n",
    "# Save to CSV\n",
    "resampled_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Resampled data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled data saved to output.csv\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import rdpcap\n",
    "import pandas as pd\n",
    "\n",
    "def pcap_to_resampled_csv(input_pcap_path, output_csv_path, resample_interval='200L'):\n",
    "    # Read packets from the pcap file\n",
    "    packets = rdpcap(input_pcap_path)\n",
    "\n",
    "    # Extract packet times and sizes\n",
    "    times = [pkt.time for pkt in packets]\n",
    "    sizes = [len(pkt) for pkt in packets]\n",
    "\n",
    "    # Normalize the time to start from 0 by subtracting the first timestamp from all timestamps\n",
    "    times = [t - times[0] for t in times]\n",
    "\n",
    "    # Create a DataFrame from the normalized times and sizes\n",
    "    df = pd.DataFrame({'Time': times, 'Size': sizes})\n",
    "\n",
    "    # Convert 'Time' to timedelta for resampling\n",
    "    df['Time'] = pd.to_timedelta(df['Time'].astype(float), unit='s')\n",
    "\n",
    "    # Set 'Time' as the index\n",
    "    df.set_index('Time', inplace=True)\n",
    "\n",
    "    # Resample and sum up the sizes for each interval\n",
    "    resampled_df = df.resample(resample_interval).sum()\n",
    "\n",
    "    # Reset index to turn the 'Time' back into a column and convert it back to seconds\n",
    "    resampled_df.reset_index(inplace=True)\n",
    "    resampled_df['Time'] = resampled_df['Time'].dt.total_seconds()\n",
    "\n",
    "    # Save to CSV\n",
    "    resampled_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Resampled data saved to {output_csv_path}\")\n",
    "\n",
    "# Example usage:\n",
    "pcap_to_resampled_csv('../../data_processed/vc_200/alexa/total3/10/10.pcap', 'output.csv', '200L')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scapy.all import rdpcap\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def resample_pcap(input_pcap_path, output_csv_path, resample_interval='200L'):\n",
    "    packets = rdpcap(input_pcap_path)\n",
    "    times = [pkt.time for pkt in packets]\n",
    "    sizes = [len(pkt) for pkt in packets]\n",
    "    times = [t - times[0] for t in times]\n",
    "    \n",
    "    df = pd.DataFrame({'Time': times, 'Size': sizes})\n",
    "    df['Time'] = pd.to_timedelta(df['Time'].astype(float), unit='s')\n",
    "    df.set_index('Time', inplace=True)\n",
    "    \n",
    "    resampled_df = df.resample(resample_interval).sum()\n",
    "    resampled_df.reset_index(inplace=True)\n",
    "    resampled_df['Time'] = resampled_df['Time'].dt.total_seconds()\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "    resampled_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "def process_subfolder(root, subfolder, output_root, resample_interval):\n",
    "    input_folder = os.path.join(root, subfolder)\n",
    "    output_folder = os.path.join(output_root, subfolder)\n",
    "    pcap_files = sorted([f for f in os.listdir(input_folder) if f.endswith('.pcap')], key=lambda x: int(x.split('.')[0]))\n",
    "    \n",
    "    for file_name in pcap_files:\n",
    "        input_pcap_path = os.path.join(input_folder, file_name)\n",
    "        output_csv_path = os.path.join(output_folder, file_name.replace('.pcap', '.csv'))\n",
    "        resample_pcap(input_pcap_path, output_csv_path, resample_interval)\n",
    "\n",
    "def parallel_resample(root_folder, output_root_folder, resample_interval='200L'):\n",
    "    subfolders = sorted([f for f in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, f))], key=lambda x: int(x))\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_subfolder, root_folder, subfolder, output_root_folder, resample_interval) for subfolder in subfolders]\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "\n",
    "# Example usage:\n",
    "parallel_resample('../../data_processed/vc_200/alexa/total3/', '../../data_processed/vc_200/alexa/resampled_02s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
